{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbee276c",
   "metadata": {},
   "source": [
    "# Application of supervised learning\n",
    "\n",
    "The \"Medical Cost Personal\" dataset, available on Kaggle, provides a rich source of information on individual patients' health insurance data, which can be instrumental in understanding the factors influencing the cost of their medical treatment. The dataset encompasses six independent features, namely age, sex, body mass index (BMI), number of children, smoking status, and region of residence. \n",
    "\n",
    "The data is in the \"data/supervised_learning_data\" folder and is available on kaggle: [https://www.kaggle.com/datasets/mirichoi0218/insurance](https://www.kaggle.com/datasets/mirichoi0218/insurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91837a5d",
   "metadata": {},
   "source": [
    "### Why Linear regression model?\n",
    "\n",
    "Linear regression is a supervised learning algorithm used when target / dependent variable continues real number. It establishes relationship between dependent variable  y and one or more independent variable  x using best fit line.\n",
    "\n",
    "Now we need to load the data, conduct different analysis and if needed preprocess the data so that we can apply the linear regression model.\n",
    "\n",
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9eb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2df505",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = Path('../../data/supervised_learning_data/')\n",
    "dataset_folder.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97601bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_folder.joinpath('insurance.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9847a3",
   "metadata": {},
   "source": [
    "### EDA approach (Exploratory Data Analysis)\n",
    "\n",
    "EDA is an approach to analyzing and summarizing datasets in order to gain insights and understand the underlying patterns and relationships within the data. \n",
    "\n",
    "#### Do we need to clean the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ef4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbbd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cddc96",
   "metadata": {},
   "source": [
    "We can see that there is no missing values using the data.info and that the values for each column seems consistent. \n",
    "We need to note however that the columns named \"children\" and \"charges\" are skewed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2f00b",
   "metadata": {},
   "source": [
    "#### Check if there are correlations between variables\n",
    "\n",
    "note : the closer from 1, the higher the correlation is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corr_data = data.corr()\n",
    "sns.heatmap(my_corr_data, annot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc306e",
   "metadata": {},
   "source": [
    "#### Using all of this we can see that :\n",
    "- The dataset, shaped as (1338,7), comprises 1338 individual patient entries (rows) and 7 attributes (columns).\n",
    "- 'Charges' is the target variable we aim to predict, while the other six (age, sex, BMI, children, smoker, and region) are the independent variables used for prediction.\n",
    "- Given the presence of multiple independent variables, a Multiple Linear Regression model is needed to best predict the 'charges' based on these variables.\n",
    "\n",
    "Attention: important to note that high correlation doesn't mean causation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1bb0a",
   "metadata": {},
   "source": [
    "#### See for exemple the correlation between sex and charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b63295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "fig = px.histogram(df, \n",
    "                   x='charges', \n",
    "                   color='sex',\n",
    "                   color_discrete_sequence=['blue', 'orange']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, \n",
    "                   x='bmi', \n",
    "                   color='sex',\n",
    "                   color_discrete_sequence=['blue', 'orange']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='bmi',y='charges',hue='sex',data=data,aspect=1.5,height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bec40d",
   "metadata": {},
   "source": [
    "We see that for most costumers the price is between 0 and 20k, and that there are more male costumer than female costumer.\n",
    "We can also see that there are more male costumers that have a greater bmi.\n",
    "\n",
    "The general trend seems to be that being overweighted will be charged more and because more males are overweighted, there is indeed a correlation between having more medical fees and being a male, though maybe small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240635fa",
   "metadata": {},
   "source": [
    "#### We are quickly looking at the correlation between charge and three interesting variables : age, smokers and regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='bmi',y='charges',hue='age',data=data,aspect=1.5,height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eebd38",
   "metadata": {},
   "source": [
    "It seems that the older they get, the higher their medical fees is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='bmi',y='charges',hue='smoker',data=data,aspect=1.5,height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='bmi',y='charges',hue='region',data=data,aspect=1.5,height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8ef0a",
   "metadata": {},
   "source": [
    "It seems that those variables that we talk about above have a correlation (that is strong for age or smoker for exemple).\n",
    "\n",
    "Then let's do a linear regression on multiple features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d057dd1",
   "metadata": {},
   "source": [
    "### Function that split and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c987b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(data, param = False, polynomial = False):\n",
    "    X = data.drop('charges',axis=1) # Independet variable\n",
    "    y = data['charges'] # dependent variable\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "\n",
    "    # model\n",
    "    model = LinearRegression(fit_intercept= param)\n",
    "    \n",
    "    #The updated version using polynomial features\n",
    "    if polynomial:\n",
    "        poly_mod = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "        X_train = poly_mod.fit_transform(X_train)\n",
    "        X_test = poly_mod.fit_transform(X_test)\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print('The score of my model is: ', model.score(X_test, Y_test))\n",
    "    print('The R squared score of my model is: ', r2_score(predictions, Y_test))\n",
    "    print('The coefficients are: ', model.coef_)\n",
    "    print('The Mean Square Error is: ', np.sqrt(mean_squared_error(predictions, Y_test)))\n",
    "\n",
    "    #Plot the corresponding graph for linearity\n",
    "    plt.plot(Y_test,predictions,'o')\n",
    "    m,b = np.polyfit(Y_test,predictions,1)\n",
    "    plt.plot(Y_test,m*Y_test+b)\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, data):\n",
    "    X = data.drop('charges',axis=1) # Independet variable\n",
    "    y = data['charges'] # dependent variable\n",
    "    kfold = 50\n",
    "    return cross_val_score(model, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d56261",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "However before doing so, as ML algorithms doesn't work with categorical data directly we need to turn it into numerical values. For these we have three possibilities: \"Dummy variable\", \"Label Encoding\" and \"One hot encoding\"\n",
    "\n",
    "To do all of them we will use the get_dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd66c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for categorical columns\n",
    "data = pd.get_dummies(data, columns = ['sex', 'smoker', 'region'],drop_first =True,\n",
    "              dtype='int8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3adfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.iloc[:, 0:4], diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145bcf1a",
   "metadata": {},
   "source": [
    "### Estimator for data with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98226325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compute(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e75b54",
   "metadata": {},
   "source": [
    "It seems that the model that returns the estimator of 0.70 % fits the data, however we can see on the graph that the relationship between the dependent and independent variable is not exactly linear.\n",
    "\n",
    "It is not the best situation and we should handle the model a bit differently so that we could get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59cc901",
   "metadata": {},
   "source": [
    "### However the model can be better\n",
    "\n",
    "In order to improve the model's accuracy there are three techniques:\n",
    "- Multicollinearity is addressed by identifying and removing highly correlated independent variables, improving model stability and interpretability.\n",
    "- Polynomial Features are used to capture more complex relationships.\n",
    "- Gradient Descent is an optimization algorithm that iteratively adjusts model parameters to minimize the difference between the predicted and actual values, boosting model accuracy.\n",
    "\n",
    "Here we will focus on polynomial features.\n",
    "\n",
    "#### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a92f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compute(data, polynomial = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9b7dd",
   "metadata": {},
   "source": [
    "Now the estimation is higher than before being at 0.84% instead of 70%.\n",
    "The graph shows also that the model seems to fit the data better which is confirmed with the mean squared error which is smaller than before.\n",
    "\n",
    "So we can see that polynomial features feat the data better as it helps with relationship between variables aren't exactly linear, which helps with enhancing the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8399f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Conducting a linear regression on this dataset was a better idea than doing a classification as it seems to feat the data better. \n",
    "\n",
    "However after:\n",
    "- exploring the data and finding correlations between inputs and targets\n",
    "- picking the linear regression model\n",
    "- scaling numeric variables and one-hot encode categorical data\n",
    "- setting aside a test set (using a fraction of the training set)\n",
    "- training the model\n",
    "- making predictions on the test set \n",
    "\n",
    "We have seen that it was necessary to optimize the problem at hand as we have done in the exemple with the  polynomial features.\n",
    "\n",
    "However as the model stills needs improvement, it might have been better to compare with other model as XGBoost regression, as it must have more parameters that we could ajust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
